{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01f71244",
   "metadata": {},
   "source": [
    "# 1. Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209fce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optional: seaborn cho plot tổng quan (có thể bỏ)\n",
    "import seaborn as sns\n",
    "\n",
    "# Make project root current working dir\n",
    "project_root = Path.cwd().parent\n",
    "os.chdir(project_root)\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06dacba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import (\n",
    "    DATA_DIR, RESULTS_DIR, VISUALIZATIONS_DIR,\n",
    "    MIN_INVENTORY_DAYS, MAX_INVENTORY_DAYS,\n",
    "    GA_POPULATION_SIZE, GA_GENERATIONS,\n",
    "    GA_CROSSOVER_PROB, GA_MUTATION_PROB,\n",
    "    REQUIRED_DATA_FILES\n",
    ")\n",
    "\n",
    "from src.engine.analyzer import InventoryAnalyzer\n",
    "from src.engine.rule_based import RuleBasedOptimizer\n",
    "from src.engine.genetic_algorithm import GeneticAlgorithmOptimizer\n",
    "from src.engine.results_manager import ResultsManager\n",
    "from src.engine.prophet_forecaster import ProphetForecaster\n",
    "\n",
    "print(\"Project components imported successfully\")\n",
    "print(f\"Configuration loaded:\")\n",
    "print(f\"   - Min inventory days: {MIN_INVENTORY_DAYS}\")\n",
    "print(f\"   - Max inventory days: {MAX_INVENTORY_DAYS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504e8a65",
   "metadata": {},
   "source": [
    "# 2. Load and Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7716b6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(project_root) / DATA_DIV if (DATA_DIV:=DATA_DIR) else Path(project_root) / DATA_DIR\n",
    "results_dir = Path(project_root) / RESULTS_DIR\n",
    "\n",
    "# Check required files\n",
    "missing_files = [f for f in REQUIRED_DATA_FILES if not (data_dir / f).exists()]\n",
    "if missing_files:\n",
    "    print(f\"Missing files: {missing_files}\")\n",
    "    print(\"Please run data generation first: python src/main.py --generate-data\")\n",
    "else:\n",
    "    print(\"All required data files found\")\n",
    "\n",
    "print(f\"\\nData directory: {data_dir}\")\n",
    "for file in REQUIRED_DATA_FILES:\n",
    "    p = data_dir / file\n",
    "    if p.exists():\n",
    "        print(f\"   {file}: {p.stat().st_size/1024:.1f} KB\")\n",
    "\n",
    "print(\"\\nLoading datasets...\")\n",
    "sales_df = pd.read_csv(data_dir / 'sales_data.csv')\n",
    "sales_df['date'] = pd.to_datetime(sales_df['date'])\n",
    "inventory_df = pd.read_csv(data_dir / 'inventory_data.csv')\n",
    "inventory_df['store_id'] = inventory_df['store_id'].astype(int)\n",
    "stores_df = pd.read_csv(data_dir / 'stores.csv')\n",
    "products_df = pd.read_csv(data_dir / 'products.csv')\n",
    "distance_matrix = pd.read_csv(data_dir / 'distance_matrix.csv', index_col=0)\n",
    "transport_cost_matrix = pd.read_csv(data_dir / 'transport_cost_matrix.csv', index_col=0)\n",
    "distance_matrix.index = distance_matrix.index.astype(int); distance_matrix.columns = distance_matrix.columns.astype(int)\n",
    "transport_cost_matrix.index = transport_cost_matrix.index.astype(int); transport_cost_matrix.columns = transport_cost_matrix.columns.astype(int)\n",
    "\n",
    "print(f\"Sales Data: {len(sales_df):,} records\")\n",
    "print(f\"Inventory Data: {len(inventory_df):,} records\")\n",
    "print(f\"Stores Data: {len(stores_df):,} stores\")\n",
    "print(f\"Products Data: {len(products_df):,} products\")\n",
    "print(f\"Distance Matrix: {distance_matrix.shape[0]}x{distance_matrix.shape[1]}\")\n",
    "print(f\"Transport Cost Matrix: {transport_cost_matrix.shape[0]}x{transport_cost_matrix.shape[1]}\")\n",
    "print(f\"Sales date range: {sales_df['date'].min()} to {sales_df['date'].max()}\")\n",
    "print(f\"Sales dtypes: date={sales_df['date'].dtype}, quantity={sales_df['quantity'].dtype}\")\n",
    "\n",
    "# Sanity schema for Prophet & inventory\n",
    "required_sales_cols = {\"date\",\"store_id\",\"product_id\",\"quantity\"}\n",
    "missing_sales_cols = required_sales_cols - set(sales_df.columns)\n",
    "if missing_sales_cols:\n",
    "    raise ValueError(f\"sales_df thiếu cột: {missing_sales_cols} (cần {sorted(list(required_sales_cols))})\")\n",
    "\n",
    "sales_df[\"store_id\"]   = sales_df[\"store_id\"].astype(int)\n",
    "sales_df[\"product_id\"] = sales_df[\"product_id\"].astype(int)\n",
    "sales_df[\"quantity\"]   = pd.to_numeric(sales_df[\"quantity\"], errors=\"coerce\").fillna(0).astype(float)\n",
    "\n",
    "possible_inv_cols = [\"quantity\",\"current_stock\",\"stock_quantity\",\"inventory_level\"]\n",
    "inventory_qty_col = next((c for c in possible_inv_cols if c in inventory_df.columns), None)\n",
    "if not inventory_qty_col:\n",
    "    raise ValueError(f\"inventory_df thiếu cột tồn kho. Cần một trong {possible_inv_cols}\")\n",
    "inventory_df[\"product_id\"] = inventory_df[\"product_id\"].astype(int)\n",
    "inventory_df[inventory_qty_col] = pd.to_numeric(inventory_df[inventory_qty_col], errors=\"coerce\").fillna(0).astype(float)\n",
    "\n",
    "# (Optional) quick peek\n",
    "print(\"\\nSample Data Overview:\")\n",
    "try:\n",
    "    display(sales_df.head())\n",
    "    display(inventory_df.head())\n",
    "    display(stores_df.head())\n",
    "    display(products_df.head())\n",
    "except Exception:\n",
    "    print(sales_df.head().to_string(index=False))\n",
    "    print(inventory_df.head().to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5499932",
   "metadata": {},
   "source": [
    "# 3. Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e286d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 9))\n",
    "    axes[0,0].hist(sales_df['quantity'], bins=30, alpha=0.7)\n",
    "    axes[0,0].set_title('Sales Quantity Distribution')\n",
    "    inv_col = inventory_qty_col\n",
    "    axes[0,1].hist(inventory_df[inv_col], bins=30, alpha=0.7)\n",
    "    axes[0,1].set_title(f'Inventory {inv_col} Distribution')\n",
    "    if 'store_id' in sales_df.columns:\n",
    "        sbs = sales_df.groupby('store_id')['quantity'].sum().sort_values(ascending=False).head(10)\n",
    "        axes[1,0].bar(range(len(sbs)), sbs.values)\n",
    "        axes[1,0].set_title('Top 10 Stores by Sales')\n",
    "    ibs = inventory_df.groupby('store_id')[inv_col].sum().sort_values(ascending=False).head(10)\n",
    "    axes[1,1].bar(range(len(ibs)), ibs.values)\n",
    "    axes[1,1].set_title('Top 10 Stores by Inventory')\n",
    "    plt.tight_layout(); plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"(Skipping EDA plots) Reason: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658970bb",
   "metadata": {},
   "source": [
    "# 4. Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9caf61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nInitializing Inventory Analyzer...\")\n",
    "analyzer = InventoryAnalyzer(\n",
    "    sales_df=sales_df,\n",
    "    inventory_df=inventory_df,\n",
    "    stores=stores_df,\n",
    "    products=products_df\n",
    ")\n",
    "\n",
    "print(\"Analyzing sales data...\")\n",
    "analysis_df = analyzer.analyze_sales_data()\n",
    "try:\n",
    "    display(analysis_df.head())\n",
    "except:\n",
    "    print(analysis_df.head().to_string(index=False))\n",
    "\n",
    "print(\"Identifying inventory imbalances (legacy analyzer)...\")\n",
    "excess_df_legacy, needed_df_legacy = analyzer.identify_inventory_imbalances()\n",
    "print(f\"Legacy: excess rows={len(excess_df_legacy)}, needed rows={len(needed_df_legacy)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da22004c",
   "metadata": {},
   "source": [
    "# 5. Prophet Forecasting → demand gaps (Prophet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a55e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nForecasting demand with Prophet...\")\n",
    "forecaster = ProphetForecaster(\n",
    "    weekly_seasonality=True,\n",
    "    yearly_seasonality=True,\n",
    "    daily_seasonality=False,\n",
    "    holidays_df=None,                 # có thể nạp vn_holidays.csv với cột ['ds','holiday']\n",
    "    seasonality_mode=\"multiplicative\",\n",
    "    interval_width=0.8\n",
    ")\n",
    "\n",
    "HORIZON_DAYS = 14\n",
    "forecast_df = forecaster.fit_predict(\n",
    "    sales_df=sales_df[[\"date\",\"store_id\",\"product_id\",\"quantity\"]],\n",
    "    horizon_days=HORIZON_DAYS,\n",
    "    regressors_df=None,               # nếu có regressors (promotion/price/discount...), nạp df vào đây\n",
    "    freq=\"D\",\n",
    "    min_points_per_series=10\n",
    ")\n",
    "\n",
    "print(f\"Forecast rows: {len(forecast_df):,}\")\n",
    "try:\n",
    "    display(forecast_df.head())\n",
    "except:\n",
    "    print(forecast_df.head().to_string(index=False))\n",
    "\n",
    "print(\"\\nAggregating forecast to horizon demand...\")\n",
    "horizon_demand = (\n",
    "    forecast_df.groupby([\"store_id\",\"product_id\"], as_index=False)[\"yhat\"]\n",
    "               .sum()\n",
    "               .rename(columns={\"yhat\":\"forecast_units_horizon\"})\n",
    ")\n",
    "\n",
    "stock_now = (\n",
    "    inventory_df.groupby([\"store_id\",\"product_id\"], as_index=False)[inventory_qty_col]\n",
    "                .sum()\n",
    "                .rename(columns={inventory_qty_col: \"current_stock\"})\n",
    ")\n",
    "\n",
    "balance = horizon_demand.merge(stock_now, on=[\"store_id\",\"product_id\"], how=\"left\").fillna({\"current_stock\": 0})\n",
    "balance[\"needed_units\"] = (balance[\"forecast_units_horizon\"] - balance[\"current_stock\"]).clip(lower=0).round().astype(int)\n",
    "balance[\"excess_units\"] = (balance[\"current_stock\"] - balance[\"forecast_units_horizon\"]).clip(lower=0).round().astype(int)\n",
    "\n",
    "needed_df_prophet = balance.loc[balance[\"needed_units\"] > 0, [\"store_id\",\"product_id\",\"needed_units\"]].copy()\n",
    "excess_df_prophet  = balance.loc[balance[\"excess_units\"] > 0, [\"store_id\",\"product_id\",\"excess_units\"]].copy()\n",
    "\n",
    "print(f\"Prophet gaps: needed={len(needed_df_prophet)} rows (sum={int(needed_df_prophet['needed_units'].sum()):,}), \"\n",
    "      f\"excess={len(excess_df_prophet)} rows (sum={int(excess_df_prophet['excess_units'].sum()):,})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edef9c9",
   "metadata": {},
   "source": [
    "# 6. Transport cost matrix deep check (fix nan_cost_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0daef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTRANSPORT COST MATRIX DEEP ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Matrix dimensions: {transport_cost_matrix.shape}\")\n",
    "print(f\"\\nMatrix sample (top-left 5x5):\")\n",
    "try:\n",
    "    display(transport_cost_matrix.iloc[:5, :5])\n",
    "except:\n",
    "    print(transport_cost_matrix.iloc[:5, :5].to_string())\n",
    "\n",
    "# Fix undefined var:\n",
    "nan_cost_count = int(transport_cost_matrix.isna().sum().sum())\n",
    "print(f\"\\nTotal NaN cost entries: {nan_cost_count}\")\n",
    "if nan_cost_count > 0:\n",
    "    nan_mask = transport_cost_matrix.isna()\n",
    "    total_diag = len(transport_cost_matrix.index)\n",
    "    diagonal_nans = sum(nan_mask.loc[i, i] for i in transport_cost_matrix.index if i in transport_cost_matrix.columns)\n",
    "    print(f\"   Diagonal NaN entries: {diagonal_nans} / {total_diag}\")\n",
    "    print(f\"   All NaN on diagonal? {'YES' if diagonal_nans == nan_cost_count else 'NO'}\")\n",
    "\n",
    "valid_vals = transport_cost_matrix.values.flatten()\n",
    "valid_vals = valid_vals[~pd.isna(valid_vals)]\n",
    "if valid_vals.size:\n",
    "    print(f\"\\nValid Cost Stats: n={valid_vals.size}, min={valid_vals.min():,.0f}, \"\n",
    "          f\"median={np.median(valid_vals):,.0f}, mean={valid_vals.mean():,.0f}, max={valid_vals.max():,.0f}\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e905f7",
   "metadata": {},
   "source": [
    "# 7. Init Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11fd297",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nInitializing Optimizers...\")\n",
    "rule_optimizer = RuleBasedOptimizer(\n",
    "    distance_matrix=distance_matrix,\n",
    "    transport_cost_matrix=transport_cost_matrix\n",
    ")\n",
    "ga_optimizer = GeneticAlgorithmOptimizer(\n",
    "    distance_matrix=distance_matrix,\n",
    "    transport_cost_matrix=transport_cost_matrix\n",
    ")\n",
    "print(\"Optimizers ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6561bd7",
   "metadata": {},
   "source": [
    "# 8. Select Demand Gaps Source (Prophet vs Legacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41b4cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PROPHET_DEMAND = True  # có thể tắt để so sánh với logic cũ\n",
    "\n",
    "use_prophet = (\n",
    "    USE_PROPHET_DEMAND\n",
    "    and len(needed_df_prophet) > 0\n",
    "    and len(excess_df_prophet) > 0\n",
    ")\n",
    "if use_prophet:\n",
    "    print(\"Using Prophet-based needed/excess for optimization.\")\n",
    "    needed_src = needed_df_prophet.copy()\n",
    "    excess_src = excess_df_prophet.copy()\n",
    "else:\n",
    "    print(\"Fallback to legacy analyzer-based needed/excess.\")\n",
    "    needed_src = needed_df_legacy.copy()\n",
    "    excess_src = excess_df_legacy.copy()\n",
    "\n",
    "for df_, cols in [(needed_src, ['store_id','product_id']),\n",
    "                  (excess_src, ['store_id','product_id'])]:\n",
    "    for c in cols:\n",
    "        if c in df_.columns:\n",
    "            df_[c] = df_[c].astype(int)\n",
    "\n",
    "# Quick key check against cost matrix\n",
    "missing_from_idx = ~excess_src['store_id'].isin(transport_cost_matrix.index)\n",
    "missing_to_col   = ~needed_src['store_id'].isin(transport_cost_matrix.columns)\n",
    "if missing_from_idx.any() or missing_to_col.any():\n",
    "    print(\"⚠️ Some store_id not present in transport_cost_matrix index/columns.\")\n",
    "    print(\"   Missing FROM index:\", sorted(excess_src.loc[missing_from_idx,'store_id'].unique().tolist()))\n",
    "    print(\"   Missing TO   cols :\", sorted(needed_src.loc[missing_to_col,'store_id'].unique().tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160abbfb",
   "metadata": {},
   "source": [
    "# 9. Run Optimizations (Rule-Based + GA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2353929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRunning Rule-Based Optimization (selected demand)...\")\n",
    "start_time = datetime.now()\n",
    "rule_transfer_plan = rule_optimizer.optimize(excess_src, needed_src)\n",
    "rule_duration = (datetime.now() - start_time).total_seconds()\n",
    "\n",
    "print(\"Running Genetic Algorithm Optimization (selected demand)...\")\n",
    "start_time = datetime.now()\n",
    "ga_pl = ga_optimizer.optimize(\n",
    "    excess_inventory=excess_src,\n",
    "    needed_inventory=needed_src,\n",
    "    population_size=GA_POPULATION_SIZE,\n",
    "    num_generations=GA_GENERATIONS,\n",
    "    crossover_prob=GA_CROSSOVER_PROB,\n",
    "    mutation_prob=GA_MUTATION_PROB,\n",
    "    tournament_size=3,\n",
    "    verbose=True\n",
    ")\n",
    "ga_transfer_plan = ga_pl if ga_pl is not None else pd.DataFrame()\n",
    "ga_duration = (datetime.now() - start_time).total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00235c0",
   "metadata": {},
   "source": [
    "# 10. Summaries & Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955769d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_plan(name, df):\n",
    "    if df is None or len(df) == 0:\n",
    "        print(f\"{name}: No transfers generated.\")\n",
    "        return None\n",
    "    total_transfers = len(df)\n",
    "    total_units = int(df['units'].sum())\n",
    "    total_cost  = float(df['transport_cost'].sum())\n",
    "    avg_cost    = (total_cost / total_units) if total_units > 0 else 0.0\n",
    "    print(f\"{name}: transfers={total_transfers}, units={total_units:,}, \"\n",
    "          f\"cost={total_cost:,.0f} VND, avg/unit={avg_cost:,.0f} VND\")\n",
    "    return dict(name=name, transfers=total_transfers, units=total_units, cost=total_cost, avg=avg_cost)\n",
    "\n",
    "print(\"\\n=== Results Summary ===\")\n",
    "rbm = summarize_plan(\"Rule-Based\", rule_transfer_plan)\n",
    "gam = summarize_plan(\"Genetic Algorithm\", ga_transfer_plan)\n",
    "print(f\"Durations: Rule-Based={rule_duration:.2f}s, GA={ga_duration:.2f}s\")\n",
    "\n",
    "for nm, plan in [(\"Rule-Based\", rule_transfer_plan), (\"Genetic\", ga_transfer_plan)]:\n",
    "    if plan is not None and len(plan):\n",
    "        zeros = int((plan['transport_cost'] == 0).sum())\n",
    "        if zeros:\n",
    "            print(f\"⚠️ {nm}: {zeros} rows have transport_cost=0 → check cost matrix & store_id mapping.\")\n",
    "\n",
    "# Pick best by minimal total cost\n",
    "best_name, best_plan = None, None\n",
    "best_cost = float('inf')\n",
    "for nm, pl in [(\"Rule-Based\", rule_transfer_plan), (\"Genetic Algorithm\", ga_transfer_plan)]:\n",
    "    if pl is not None and len(pl):\n",
    "        c = pl['transport_cost'].sum()\n",
    "        if c < best_cost:\n",
    "            best_cost, best_name, best_plan = c, nm, pl\n",
    "\n",
    "if best_plan is not None:\n",
    "    print(f\"\\nBest: {best_name} | cost={best_cost:,.0f} VND | transfers={len(best_plan)} | units={int(best_plan['units'].sum()):,}\")\n",
    "    try:\n",
    "        display(best_plan.head(10))\n",
    "    except:\n",
    "        print(best_plan.head(10).to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNo valid plan produced. Check inputs & cost matrix.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5795fd",
   "metadata": {},
   "source": [
    "# 11. Impact Analysis (using analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad6bdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_plan is not None and len(best_plan):\n",
    "    print(f\"\\nAnalyzing Impact of {best_name} plan...\")\n",
    "    post_transfer_impact, post_analysis = analyzer.evaluate_plan_impact(best_plan)\n",
    "    try:\n",
    "        display(post_transfer_impact)\n",
    "    except:\n",
    "        print(post_transfer_impact.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae150291",
   "metadata": {},
   "source": [
    "# 12. Final Summary & Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a02993",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFINAL OPTIMIZATION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"   • Total stores: {stores_df['store_id'].nunique()}\")\n",
    "print(f\"   • Total products: {products_df['product_id'].nunique()}\")\n",
    "print(f\"   • Prophet Needed: {len(needed_df_prophet)} ({int(needed_df_prophet['needed_units'].sum()):,})\")\n",
    "print(f\"   • Prophet Excess : {len(excess_df_prophet)} ({int(excess_df_prophet['excess_units'].sum()):,})\")\n",
    "if rbm:\n",
    "    print(f\"   • Rule-Based: cost={rbm['cost']:,.0f}, units={rbm['units']:,.0f}, transfers={rbm['transfers']}\")\n",
    "if gam:\n",
    "    print(f\"   • GA        : cost={gam['cost']:,.0f}, units={gam['units']:,.0f}, transfers={gam['transfers']}\")\n",
    "if best_plan is not None:\n",
    "    print(f\"   • Recommended: {best_name} (cost={best_cost:,.0f})\")\n",
    "\n",
    "# Save results\n",
    "save_results = True\n",
    "if save_results and best_plan is not None:\n",
    "    results_dir.mkdir(exist_ok=True)\n",
    "    best_plan_path = results_dir / 'notebook_best_transfer_plan.csv'\n",
    "    best_plan.to_csv(best_plan_path, index=False)\n",
    "    print(f\"\\nSaved best plan → {best_plan_path}\")\n",
    "\n",
    "    # Comparison table if both exist\n",
    "    comp = []\n",
    "    if rbm: comp.append({\"Algorithm\":\"Rule-Based\", **{k:v for k,v in rbm.items() if k!='name'}})\n",
    "    if gam: comp.append({\"Algorithm\":\"Genetic Algorithm\", **{k:v for k,v in gam.items() if k!='name'}})\n",
    "    if comp:\n",
    "        comp_df = pd.DataFrame(comp)\n",
    "        comp_path = results_dir / 'notebook_algorithm_comparison.csv'\n",
    "        comp_df.to_csv(comp_path, index=False)\n",
    "        print(f\"Saved comparison → {comp_path}\")\n",
    "\n",
    "    summary = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'best_algorithm': best_name,\n",
    "        'total_cost': float(best_cost),\n",
    "        'total_transfers': int(len(best_plan)),\n",
    "        'total_units': int(best_plan['units'].sum()),\n",
    "        'prophet_excess_rows': int(len(excess_df_prophet)),\n",
    "        'prophet_needed_rows': int(len(needed_df_prophet))\n",
    "    }\n",
    "    summary_path = results_dir / 'notebook_analysis_summary.json'\n",
    "    with open(summary_path, 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(f\"Saved summary → {summary_path}\")\n",
    "\n",
    "print(\"\\nAnalysis Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe198ab",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
